<!DOCTYPE html>

<HTML>
<HEAD>
  <META content="IE=5.0000" http-equiv="X-UA-Compatible">
  <META name="description" content="Zhonqin Wang's home page"> 
  <META http-equiv="Content-Type" content="text/html; charset=gb2312">
  <LINK href="files/doc.css" 
    rel="stylesheet" type="text/css"> 
  <TITLE>Zhonqin Wang</TITLE> 
  <META name="GENERATOR" content="MSHTML 11.00.10570.1001">
  <TITLE>line-height</TITLE> 
  <style>
    .line-height-1 {line-height: 0.1;}
    .line-height-2 {line-height: 0.2;}
    .line-height-3 {line-height: 0.3;}
    .line-height-4 {line-height: 0.4;}
    .line-height-5 {line-height: 0.5;}
    .line-height-6 {line-height: 0.6;}
    .line-height-7 {line-height: 0.7;}
    .line-height-8 {line-height: 0.8;}
    .line-height-9 {line-height: 0.9;}
    .line-height-10 {line-height: 1;}
    .line-height-11 {line-height: 1.1;}
    .line-height-12 {line-height: 1.2;}
    .line-height-13 {line-height: 1.3;}
    .line-height-14 {line-height: 1.4;}
    .line-height-15 {line-height: 1.5;}
    .line-height-20 {line-height: 2;}
  </style>
  <title>一半左对齐一半右对齐</title>
  <style>
      .container {
          display: flex;
          justify-content: space-between;
      }
      .left {
          text-align: left;
          width: 70%;
      }
      .right {
          text-align: right;
          width: 30%;
      }
  </style>
</HEAD>


<BODY> 
  <DIV id="layout-content" style="margin-top: 25px;">
  <TABLE>
    <TBODY>
    <TR>
      <TD width="670">
        <DIV id="toptitle">
        <H1>Dr. Zhonqin Wang &nbsp;</H1></DIV>
        <BR>
        <BR>
        <BR> Email:  
        <A class="line-height-15" href="mailto:zhongqin.wang@uts.edu.au"> zhongqin.wang@uts.edu.au</A>; 
        <BR> Phone: 
        <A class="line-height-15" href="+61 0416167758"> +61 0416167758</A>;
        <BR> Github: 
        <A class="line-height-15" href="https://github.com/Zhongqin-Wang">https://github.com/Zhongqin-Wang</A>;
        <BR> Google scholar:
        <A class="line-height-15" href="https://scholar.google.com/citations?user=F9UMFwIAAAAJ&hl=en">https://scholar.google.com</A>
        <BR><BR></P>
      </TD>
      <TD>
        <IMG width="150" src="files/person_photo.jpg" border="0">
      </TD>
    </TR>
    <TR></TR></TBODY>
  </TABLE>
  <DIV id="layout-content" style="margin-top: 25px;">


  <H2>RESEARCH INTERESTS</H2>
  <P class="line-height-15"> I specialize in designing Contactless, Sensorless, and Wireless sensing solutions beyond vision, aiming to 
    build commercialized sensing applications for a smart and privacy-protected life. My current research interests 
    include:
  </P>

  <ul>
    <li class="line-height-5">Wireless Sensing and Communication</li>
    <li class="line-height-5">Contactless Healthcare and Eldercare</li>
    <li class="line-height-5">Radio-Visual Joint Learning and Sensing</li>
    <li class="line-height-5">Contactless Healthcare and Eldercare</li>
  </ul>

  <H2>WORK EXPERIENCE</H2>
  <div class="container">
    <div class="left"><b>University of Technology Sydney, Australia</b></div>
    <div class="right">Feb. 2024 - Present</div>
  </div>
  <p class="line-height-15"><i>Research Fellow supervised by Prof. Andrew Zhang</i></p>
  <ul>
    <li class="line-height-5">Researching</li>
    <li class="line-height-5">Master/PhD student supervision</li>
  </ul>

  <div class="container">
    <div class="left"><b>Capital Normal University, Beijing, China</b></div>
    <div class="right">Dec. 2021 - Jan. 2024</div>
  </div>
  <p class="line-height-15"><i>Lecturer at College of Information and Engineering</i></p>
  <ul>
    <li class="line-height-5">Researching</li>
    <li class="line-height-5">Teaching</li>
    <li class="line-height-5">Master student supervision</li>
  </ul>

  <div class="container">
    <div class="left"><b>University of Technology Sydney, Australia</b></div>
    <div class="right">Sep. 2021 - Jun. 2022</div>
  </div>
  <p class="line-height-15"><i>Research Associate supervised by Prof. Min Xu</i></p>
  <ul>
    <li class="line-height-5">Developed an elderly healthcare system using commercial 
      off-the-shelf millimeter-wave devices</li>
    <li class="line-height-15">Led the development of key functionalities, including 
      moving object tracking, vital signs estimation, fall detection, stationary object localization, and people counting</li>
    <li class="line-height-5">Designed low-computational cutting-edge algorithms 
      to enhance the real-time performance of the system</li>
    <li class="line-height-5">Provided valuable mentorship and guidance to Ph.D. 
      students</li>
  </ul>

  <div class="container">
    <div class="left"><b>University of Technology Sydney, Australia</b></div>
    <div class="right">Jan. 2021 – Jun. 2021</div>
  </div>
  <p class="line-height-15"><i>Research Engineer supervised by Prof. Andrew Zhang</i></p>
  <ul>
    <li class="line-height-5">Designed a novel device-free WiFi tracking scheme</li>
    <li class="line-height-5">Implemented a real-time tracking demonstration system
      (Demo video available at: 
      <A href="https://youtu.be/oIPGrRmY-uc">https://youtu.be/oIPGrRmY-uc</A>)</li>
    <li class="line-height-5">Published the research outcome in an A* top journal</li>
  </ul>

  <div class="container">
    <div class="left"><b>University of Technology Sydney, Australia</b></div>
    <div class="right">Jul. 2020 – Dec. 2020</div>
  </div>
  <p class="line-height-15"><i>Research Assistant supervised by Prof. Andrew Zhang</i></p>
  <ul>
    <li class="line-height-5">Established a WiFi hardware platform for data collection </li>
    <li class="line-height-5">Reproduced and evaluated previous research works on 
      passive human tracking using WiFi signals</li>
  </ul>



  <H2>EDUCATION</H2>
  <div class="container">
    <div class="left"><b>University of Technology Sydney, Australia</b></div>
    <div class="right">Jan. 2017 – Dec. 2020</div>
  </div>
  <p class="line-height-17">School of Electrical and Data Engineering</p>
  <p class="line-height-1"><i>Ph.D. in Engineering supervised by Prof. Min Xu</i></p>
  <p class="line-height-13">Thesis: Computer Vision-assisted Battery-free RFID 
    Systems for Object Recognition, Localization and Orientation</p>

  <div class="container">
    <div class="left"><b>Nanjing University of Posts and Telecommunications, China</b></div>
    <div class="right">Sep. 2015 – Jun. 2020</div>
  </div>
  <p class="line-height-17">School of Internet of Things</p>
  <p class="line-height-1"><i>Ph.D. in Information Network supervised by Prof. Guoliang Chen</i></p>
  <p class="line-height-13">Thesis: Research on Object Position Sensing and Multi-Tag Mutual 
    Coupling Suppression in Battery-free RFID</p>

  <div class="container">
    <div class="left"><b>University of Technology Sydney, Australia</b></div>
    <div class="right">Sep. 2011 – Mar. 2014</div>
  </div>
  <p class="line-height-17">Nanjing University of Posts and Telecommunications, China</p>
  <p class="line-height-1"><i>School of Computer Science and Technology</i></p>
  <p class="line-height-13">M.S. in Computer Software and Theory supervised by Prof. Ning Ye</p>

  <H2>PUBLICATIONS</H2>
  <p>[1] <b>Zhongqin Wang</b>, J. Andrew Zhang, Min Xu and Y. Jay Guo. Single-Target 
    Real-Time Passive WiFi Tracking, <i>IEEE Transactions on Mobile Computing</i>, vol.22, 
    no. 6, pp. 3724-3742, 2023. <i>(CORE A*, JCR Q1, IF: 6.075)</i></p>
  <p>[2] Kuangda Chen, J. Andrew Zhang, <b>Zhongqin Wang</b> and Y. Jay Guo. Development 
    of an Uplink Sensing Demonstrator for Perceptive Mobile Networks. <i>In Proc. of IEEE 
    ISCIT</i>, pp. 191-196, 2023.</p>
  <p>[3] Yingqi Wang, <b>Zhongqin Wang</b>, J. Andrew Zhang, Haimin Zhang, Min Xu. 
    Vital Sign Monitoring in Dynamic Environment via mmWave Radar and Camera Fusion, 
    <i>IEEE Transactions on Mobile Computing</i>, pp. 1-17, 2023, doi:10.1109/
    TMC.2023.3288850.</p>
  <p>[4] <b>Zhongqin Wang</b>, J. Andrew Zhang, Fu Xiao, Min Xu. Accurate AoA 
    Estimation for RFID Tag Array with Mutual Coupling, <i>IEEE Internet of Things Journal</i>
    , vol. 9, no. 15, pp. 12954-12972, 2022. <i>(JCR Q1, IF: 10.238)</i></p>
  <p>[5] <b>Zhongqin Wang</b>, Min Xu, Ning Ye, Ruchuan Wang, Haiping Huang and Fu Xiao. 
    Computer Vision-assisted 3D Object Localization via COTS RFID Devices and a Monocular 
    Camera, <i>IEEE Transactions on Mobile Computing</i>, vol. 20, no. 3, pp. 893 - 908, 
    2021. <i>(CORE A*, JCR Q1, IF: 6.075)</i></p>
  <p>[6] <b>Zhongqin Wang</b>, Min Xu, Fu Xiao. Recognizing 3D Orientation of a Two-RFID-Tag
     Labeled Object in Multipath Environments Using Deep Transfer Learning. 
     <i>In Proc. of IEEE ICDCS</i>, pp. 652-662, 2021. <i>(CORE A, 97/489)</i></p>
  <p>[7] <b>Zhongqin Wang</b>, Min Xu, Ning Ye, Ruchuan Wang, Haiping Huang and Fu Xiao.
     RF-Mirror: Mitigating Mutual Coupling Interference in Two-Tag Array Labeled RFID 
     Systems. <i>In Proc. of IEEE SECON</i>, pp. 1-9, 2020. <i>(CORE B, 36/129)</i></p>
  <p>[8] <b>Zhongqin Wang</b>, Min Xu, Ning Ye, Ruchuan Wang and Haiping Huang. RF-Focus:
     Computer Vision-assisted Region-of-interest RFID Tag Recognition and Localization in
      Multipath-prevalent Environments. <i>Proceedings of the ACM on Interactive, Mobile, 
        Wearable and Ubiquitous Technologies</i>, vol.3, no. 1, pp. 29, 2019. 
         <i>(UbiComp, CORE A*)</i></p>
  <p>[9] <b>Zhongqin Wang</b>, Min Xu, Ning Ye, Ruchuan Wang and Haiping Huang. RF-MVO: 
    Simultaneous 3D Object Localization and Camera Trajectory Recovery Using RFID Devices
     and a 2D Monocular Camera. <i>In Proc. of IEEE ICDCS</i>, pp. 534-544, 2018. 
     <i>(CORE A, 78/378)</i></p>
  <p>[10] <b>Zhongqin Wang</b>, Fu Xiao, Ning Ye, Ruchuan Wang and Panlong Yang. 
    A See-Through-wall System for Device-free Human Motion Sensing Based on Battery-free 
    RFID, <i>ACM Transactions on Embedded Computing Systems</i>, vol. 17, no. 1, pp. 
    1-21, 2017. <i>(CORE B, JCR Q3, IF: 1.886)</i></p>
  <p>[11] Fu Xiao, <b>Zhongqin Wang</b>, Ning Ye, Ruchuan Wang and Xiang-Yang Li. One 
    More Tag Enables Fine-Grained RFID Localization and Tracking, <i>IEEE/ACM Transactions 
      on Networking</i>, vol. 26, no. 1, pp. 161-174, 2017. <i>(CORE A*, JCR Q1, IF: 3.796)</i></p>
  <p>[12] <b>Zhongqin Wang</b>, Ning Ye, Reza Malekiand, Fu Xiao and Ruchuan Wang. 
    TrackT: Accurate Tracking of RFID Tags with mm-level Accuracy Using First-order Taylor 
    Series Approximation, <i>Ad Hoc Networks</i>, vol. 53, pp. 132-144, 2016. 
    <i>(JCR Q1, IF: 4.816)</i></p>
  <p>[13] <b>Zhongqin Wang</b>, Ning Ye, Reza Malekian, Ruchuan Wang and Peng Li.
     TMicroscope: Behavior Perception Based on the Slightest RFID Tag Motion. 
     <i>Elektronika ir Elektrotechnika</i>, vol. 22, no. 2, pp.114-122, 2016. 
     <i>(JCR Q3, IF: 1.059)</i></p>

  <H2>PROFESSIONAL SERVICES</H2>
  <ul>
    <li class="line-height-5">TPC Member, Workshop on Integrated Sensing and 
      Communication at IEEE ICC, 2023</li>
    <li class="line-height-5">Guest Editor, Special Issue "Precise Indoor 
      Positioning and Navigation" of Applied Sciences, 2022</li>
    <li class="line-height-5">Reviewer, IEEE Journal of Selected Topics in Signal Processing, 2021</li>
    <li class="line-height-5">Reviewer, IJCAI-PRICAI, 2020</li>
    <li class="line-height-5">Reviewer, IEEE Access</li>
    <li class="line-height-5">Reviewer, IET Communications</li>
    <li class="line-height-5">Reviewer, Measurements</li>
  </ul>

     
  <H2>Publications</H2>
    <table class="pub_table">
    <!-- <tbody> -->

      <tr>
        <td class="pub_td1"><img src="files/PaperFig/kosmos2.png" class="papericon"></td>
        <td 
          class="pub_td2">&ast;<u>Zhiliang Peng</u>, &ast;Wenhui Wang, &ast;Li Dong, Yaru Hao, Shaohan Huang, Shuming Ma, Furu Wei
          <br><b>Kosmos-2: Grounding Multimodal Large Language Models to the World</b>
          <br>
          [<a href="https://arxiv.org/abs/2306.14824">Paper</a>]
          [<a href="https://aka.ms/kosmos-2-demo">Demo</a>]
          [<a href="https://github.com/microsoft/unilm/tree/master/kosmos-2">Code</a>]
          <img src="https://img.shields.io/github/stars/microsoft/unilm?style=social">
          <br>
        </td>
      </tr>

      <tr>
        <td class="pub_td1"><img src="files/PaperFig/g2sd.png" class="papericon"></td>
        <td 
          class="pub_td2">&ast;Wei Huang, &ast;<u>Zhiliang Peng</u>, Li Dong, Furu Wei, Jianbin Jiao, Qixiang Ye
          <br><b>Generic-to-Specific Distillation of Masked Autoencoders</b>
          <br>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2023
          <br>
          [<a href="https://arxiv.org/abs/2302.14771">Paper</a>]
          [<a href="https://github.com/pengzhiliang/G2SD">Code</a>]
          <img src="https://img.shields.io/github/stars/pengzhiliang/G2SD?style=social">
          <br>
        </td>
      </tr>

      <tr>
        <td class="pub_td1"><img src="files/PaperFig/Conformer_tpami.png" class="papericon"></td>
        <td 
          class="pub_td2"><u>Zhiliang Peng</u>, Zonghao Guo, Wei Huang, Yaowei Wang, Lingxi Xie, Jianbin Jiao, Qixiang Ye
          <br><b>Conformer: Local features coupling global representations for visual recognition and detection</b>
          <br>IEEE Transactions on Pattern Analysis and Machine Intelligence, 2023
          <br>
          [<a href="https://doi.org/10.1109/TPAMI.2023.3243048">Paper</a>]
          [<a href="https://github.com/pengzhiliang/Conformer">Code</a>]
          <img src="https://img.shields.io/github/stars/pengzhiliang/Conformer?style=social">
          <br>
        </td>
      </tr>

      <tr>
        <td class="pub_td1"><img src="files/PaperFig/maskdistill.png" class="papericon"></td>
        <td 
          class="pub_td2"><u>Zhiliang Peng</u>, Li Dong, Hangbo Bao, Qixiang Ye, Furu Wei
          <br><b>A Unified View of Masked Image Modeling</b>
          <br> Transactions on Machine Learning Research, 2023
          <br>
          [<a href="https://openreview.net/pdf?id=wmGlMhaBe0">Paper</a>]
          [<a href="https://github.com/microsoft/unilm/blob/master/unimim">Code</a>]
        </td>
      </tr>

      <tr>
        <td class="pub_td1"><img src="files/PaperFig/magneto.png" class="papericon"></td>
        <td 
          class="pub_td2">Hongyu Wang, Shuming Ma, Shaohan Huang, Li Dong, Wenhui Wang, <u>Zhiliang Peng</u>, Yu Wu, Payal Bajaj, Saksham Singhal, Alon Benhaim, Barun Patra, Zhun Liu, Vishrav Chaudhary, Xia Song, Furu Wei
          <br><b>Foundation Transformers</b>
          <br>International Conference on Machine Learning, 2023
          <br>
          [<a href="https://arxiv.org/abs/2210.06423">arXiv preprint</a>]
        </td>
      </tr>

      <tr>
        <td class="pub_td1"><img src="files/PaperFig/beit3.png" class="papericon"></td>
        <td 
          class="pub_td2">Wenhui Wang, Hangbo Bao, Li Dong, Johan Bjorck, <u>Zhiliang Peng</u>, Qiang Liu, Kriti Aggarwal, Owais Khan Mohammed, Saksham Singhal, Subhojit Som, Furu Wei
          <br><b>Image as a Foreign Language: BEiT Pretraining for All Vision and Vision-Language Tasks</b>
          <br>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2023
          <br>
          [<a href="https://arxiv.org/abs/2208.10442">Paper</a>]
          [<a href="https://github.com/microsoft/unilm/blob/master/beit3">Code</a>]
          <img src="https://img.shields.io/github/stars/microsoft/unilm?style=social">
        </td>
      </tr>

      <tr>
        <td class="pub_td1"><img src="files/PaperFig/beit2.png" class="papericon"></td>
        <td 
          class="pub_td2"><u>Zhiliang Peng</u>, Li Dong, Hangbo Bao, Qixiang Ye, Furu Wei
          <br><b>BEiT v2: Masked Image Modeling with Vector-Quantized Visual Tokenizers</b>
          <br>
          [<a href="https://arxiv.org/abs/2208.06366">arXiv preprint</a>]
          [<a href="http://aka.ms/beit2">Code</a>]
          <img src="https://img.shields.io/github/stars/microsoft/unilm?style=social">
        </td>
      </tr>

      <tr>
        <td class="pub_td1"><img src="files/PaperFig/imTED.png" class="papericon"></td>
        <td 
          class="pub_td2">Xiaosong Zhang, Feng Liu, <u>Zhiliang Peng</u>, Zonghao Guo, Fang Wan, Xiangyang Ji, Qixiang Ye
          <br><b>Integral Migrating Pre-trained Transformer Encoder-decoders for Visual Object Detection</b>
          <br>
          [<a href="https://arxiv.org/abs/2205.09613">arXiv preprint</a>]
        </td>
      </tr>


      <tr>
        <td class="pub_td1"><img src="files/PaperFig/Conformer.png" class="papericon"></td>
        <td 
          class="pub_td2"><u>Zhiliang Peng</u>, Wei Huang, Shanzhi Gu, Lingxi Xie, Yaowei Wang, Jianbin Jiao, Qixiang Ye
          <br><b>Conformer: Local features coupling global representations for visual recognition</b>
          <br>Proceedings of the IEEE/CVF International Conference on Computer Vision, 2021
          <br>
          [<a href="https://openaccess.thecvf.com/content/ICCV2021/html/Peng_Conformer_Local_Features_Coupling_Global_Representations_for_Visual_Recognition_ICCV_2021_paper.html">Paper</a>]
          [<a href="https://github.com/pengzhiliang/Conformer">Code</a>]
          <img src="https://img.shields.io/github/stars/pengzhiliang/Conformer?style=social">
          <br>
        </td>
      </tr>

      <tr>
        <td class="pub_td1"><img src="files/PaperFig/tscam.png" class="papericon"></td>
        <td 
          class="pub_td2">Wei Gao, Fang Wan, Xingjia Pan, <u>Zhiliang Peng</u>, Qi Tian, Zhenjun Han, Bolei Zhou, Qixiang Ye
          <br><b>TS-CAM: Token Semantic Coupled Attention Map for Weakly Supervised Object Localization</b>
          <br>Proceedings of the IEEE/CVF International Conference on Computer Vision, 2021
          <br>
          [<a href="https://openaccess.thecvf.com/content/ICCV2021/html/Gao_TS-CAM_Token_Semantic_Coupled_Attention_Map_for_Weakly_Supervised_Object_ICCV_2021_paper.html">Paper</a>]
          [<a href="https://github.com/vasgaowei/TS-CAM">Code</a>]
          <img src="https://img.shields.io/github/stars/vasgaowei/TS-CAM?style=social">
          <br>
        </td>
      </tr>

      <tr>
        <td class="pub_td1"><img src="files/PaperFig/LDA.png" class="papericon"></td>
        <td 
          class="pub_td2"><u>Zhiliang Peng</u>, Wei Huang, Zonghao Guo, Xiaosong Zhang, Jianbin Jiao, Qixiang Ye
          <br><b>Long-tailed Distribution Adaptation</b>
          <br>Proceedings of the 29th ACM International Conference on Multimedia, 2021
          <br>
          <!-- [<a href="https://dl.acm.org/doi/10.1145/3474085.3475479">Paper</a>] -->
          [<a href="https://arxiv.org/abs/2110.02686">Paper</a>]
          [<a href="https://github.com/pengzhiliang/LDA">Code</a>]
          <br>
        </td>
      </tr>
    <!-- </tbody> -->
    </table>

    <!-- <br>
    <H2>Awards</H2>
        <LI>	Excellent Student Scholarship, Chinese Academy of Sciences, 2020.  </LI> -->
  <H2>Github Statistics</Source></H2>
      <td class="pub_td1"><img src="https://github-readme-stats.vercel.app/api?username=pengzhiliang&show_icons=true&include_all_commits=true&title_color=2c86ea&icon_color=2c86ea&text_color=00c800&bg_color=00000000"></td>
    
  
  <br> <br> 
  <H2>Statistics</H2>
  <script type="text/javascript" src="//rf.revolvermaps.com/0/0/8.js?i=5063gq35g0n&amp;m=0&amp;c=ff0000&amp;cr1=ffffff&amp;f=arial&amp;l=33" async="async"></script>

</BODY>
</HTML>
